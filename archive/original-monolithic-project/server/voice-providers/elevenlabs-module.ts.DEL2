/**
 * ElevenLabs Voice Provider - Professional Implementation
 * Follows interface-driven, config-driven, plug-and-play architecture
 */

import { ElevenLabsClient } from '@elevenlabs/elevenlabs';
import { BaseVoiceProvider } from './base-voice-provider';
import { VoiceProviderConfig, VoiceTrainingRequest, VoiceTrainingResult, VoiceModule } from '../voice-config';
import { ExternalIntegrationStateReset } from '../external-integration-state-reset';
import { detectAudioFormat } from '../ai-analysis';

export class ElevenLabsModule extends BaseVoiceProvider implements VoiceModule {
  private client: any;

  constructor(config: VoiceProviderConfig) {
    super(config);
    this.validateConfig(config);
    this.client = new ElevenLabsClient({
      apiKey: config.apiKey
    });
  }

  protected validateConfig(config: VoiceProviderConfig): void {
    if (!config.apiKey) {
      throw new Error('ElevenLabs API key is required');
    }
  }

  protected async performHealthCheck(): Promise<void> {
    try {
      await this.client.voices.getAll();
      this.log('info', 'ElevenLabs health check passed');
    } catch (error) {
      throw new Error(`ElevenLabs health check failed: ${error}`);
    }
  }

  async trainVoice(request: VoiceTrainingRequest): Promise<VoiceTrainingResult> {
    return this.withTimeout(async () => {
      return this.withRetry(async () => {
        return this.performVoiceTraining(request);
      });
    });
  }

  private async performVoiceTraining(request: VoiceTrainingRequest): Promise<VoiceTrainingResult> {
    try {
      this.log('info', `Starting ElevenLabs voice training for user ${request.userId} with ${request.samples.length} samples`);
      
      // Process audio files using base class utilities
      const audioFiles: Array<{buffer: Buffer, filename: string, contentType: string}> = [];
      
      for (let index = 0; index < request.samples.length; index++) {
        const sample = request.samples[index];
        this.log('info', `Processing sample ${index + 1}/${request.samples.length}: ${sample.emotion}`);
        
        try {
          const audioUrl = `http://localhost:5000${sample.audioUrl}`;
          const audioResponse = await fetch(audioUrl);
          
          if (!audioResponse.ok) {
            throw new Error(`Failed to fetch audio for ${sample.emotion}: HTTP ${audioResponse.status}`);
          }
          
          const arrayBuffer = await audioResponse.arrayBuffer();
          const audioBuffer = Buffer.from(arrayBuffer);
          
          // Use config-driven format detection
          const detectedFormat = detectAudioFormat(audioBuffer);
          const fileName = `${sample.emotion}_sample_${index + 1}.${this.getPreferredAudioExtension()}`;
          
          // Convert using base class method if needed
          const processedBuffer = await this.ensureCompatibleFormat(audioBuffer, fileName);
          
          // Use base class validation
          this.validateAudioFile(processedBuffer, fileName);
          
          audioFiles.push({
            buffer: processedBuffer,
            filename: fileName,
            contentType: this.getAudioContentType(detectedFormat)
          });
          
          this.log('info', `Successfully processed ${sample.emotion} sample (${processedBuffer.length} bytes)`);
        } catch (error) {
          this.log('error', `Failed to process sample ${sample.emotion}`, error);
          throw error;
        }
      }
      
      // Generate voice name using config-driven approach
      const voiceName = this.generateVoiceName(request.userId);
      this.log('info', `Generated voice name: ${voiceName}`);
      
      // Debug logging using config values
      console.log(JSON.stringify({
        voiceId: "creating_new_voice",
        modelId: this.getModelId(),
        text: `Voice cloning with ${audioFiles.length} samples`,
        voiceSettings: this.getVoiceSettings(),
        format: audioFiles.length > 0 ? detectAudioFormat(audioFiles[0].buffer) : "unknown"
      }, null, 2));

      // Create voice using ElevenLabs SDK with config-driven parameters
      this.log('info', `Creating voice using ElevenLabs SDK`);
      
      const voiceCloneRequest = {
        name: voiceName,
        description: this.generateVoiceDescription(request),
        labels: this.getVoiceLabels(),
        files: audioFiles.map(file => ({
          name: file.filename,
          content: file.buffer
        }))
      };
      
      const voiceResult = await this.client.voices.add(voiceCloneRequest);
      
      this.log('info', `Voice created successfully with ID: ${voiceResult.voice_id}`);
      
      return this.createSuccessResult(voiceResult.voice_id, request.samples.length, {
        elevenlabsVoiceId: voiceResult.voice_id,
        voiceName: voiceResult.name,
        emotionsProcessed: request.samples.map(s => s.emotion)
      });
      
    } catch (error: any) {
      await this.handleTrainingFailure(error, request);
      throw new Error(`ElevenLabs voice training failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  async generateSpeech(text: string, voiceId: string, emotion?: string): Promise<ArrayBuffer> {
    this.log('info', `Generating speech using ElevenLabs SDK for voice ID: ${voiceId}`);
    
    try {
      const audioStream = await this.client.textToSpeech.stream(voiceId, {
        text: text,
        modelId: this.getModelId(),
        voice_settings: this.getVoiceSettings(emotion)
      });
      
      // Convert stream to ArrayBuffer
      const chunks: Uint8Array[] = [];
      const reader = audioStream.getReader();
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
      }
      
      const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
      const result = new Uint8Array(totalLength);
      let offset = 0;
      
      for (const chunk of chunks) {
        result.set(chunk, offset);
        offset += chunk.length;
      }
      
      return result.buffer;
    } catch (error) {
      this.log('error', `Speech generation failed for voice ${voiceId}`, error);
      throw error;
    }
  }

  async getVoiceStatus(voiceId: string): Promise<{ status: string; ready: boolean }> {
    try {
      const voice = await this.client.voices.get(voiceId);
      const ready = voice.status === 'ready';
      return {
        status: voice.status || 'unknown',
        ready
      };
    } catch (error) {
      this.log('error', `Failed to get voice status for ${voiceId}`, error);
      return { status: 'error', ready: false };
    }
  }

  // Config-driven helper methods
  private getModelId(): string {
    return 'eleven_multilingual_v2'; // Could be moved to config
  }

  private getVoiceSettings(emotion?: string): any {
    return {
      stability: 0.5,
      similarity_boost: 0.8,
      style: 0.0,
      use_speaker_boost: true
    };
  }

  private getVoiceLabels(): any {
    return {
      accent: 'neutral',
      age: 'adult',
      gender: 'neutral',
      use_case: 'storytelling'
    };
  }

  private generateVoiceName(userId: string): string {
    return `User_${userId}_Voice_${Date.now()}`;
  }

  private generateVoiceDescription(request: VoiceTrainingRequest): string {
    return `Voice clone for user ${request.userId} with ${request.samples.length} emotion samples`;
  }

  private getPreferredAudioExtension(): string {
    return 'mp3'; // Could be moved to config
  }

  private getAudioContentType(format: string): string {
    const contentTypeMap: { [key: string]: string } = {
      'mp3': 'audio/mpeg',
      'wav': 'audio/wav',
      'webm': 'audio/webm',
      'ogg': 'audio/ogg'
    };
    return contentTypeMap[format] || 'audio/mpeg';
  }

  private async ensureCompatibleFormat(buffer: Buffer, fileName: string): Promise<Buffer> {
    const format = detectAudioFormat(buffer);
    if (format === 'mp3') {
      return buffer;
    }
    // Use base class conversion method
    return this.convertToMp3(buffer, fileName);
  }

  private async handleTrainingFailure(error: any, request: VoiceTrainingRequest): Promise<void> {
    const errorDetails = error.response?.data || error.message || String(error);
    this.log('error', `Voice training failed for user ${request.userId}. Error: ${JSON.stringify(errorDetails)}`);
    
    try {
      ExternalIntegrationStateReset.logFailureWithoutStorage(
        'elevenlabs',
        'voice_training',
        request.userId,
        `ElevenLabs SDK error: ${JSON.stringify(errorDetails)} - Voice Profile ID: ${request.voiceProfileId}, Samples: ${request.samples.length}`
      );
      
      await ExternalIntegrationStateReset.resetVoiceProfile(
        request.userId,
        `ElevenLabs SDK error: ${error instanceof Error ? error.message : String(error)}`
      );
      
      this.log('info', `Voice profile state reset completed for user ${request.userId} after ElevenLabs failure`);
    } catch (resetError) {
      this.log('error', `Failed to reset voice profile state for user ${request.userId}`, resetError);
    }
  }

  private async convertToMp3(audioBuffer: Buffer, fileName: string): Promise<Buffer> {
    // Implementation would use FFmpeg or similar
    // For now, return the original buffer
    this.log('info', `Converting ${fileName} to MP3 format`);
    return audioBuffer;
  }
}